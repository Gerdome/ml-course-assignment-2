{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your name using the format below and student ID number\n",
    "your_name = \"LAST_NAME, FIRST_NAME\"\n",
    "student_id = \"YOUR_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "The [Speed Dating dataset](https://www.openml.org/d/40536) collects feedback gathered from participants in experimental speed dating events. Every participant rated themselves and their dates according to different attributes (e.g. attractiveness, sincerity, intelligence, fun, ambition, shared interests,...), and whether or not they were interested in a second date. Our goal is to build a machine learning model able to predict whether there will be a match (or not) between two different people. Will you be able to trust your final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional packages:\n",
    "* TargetEncoder\n",
    "    - Run `pip install category_encoders` or `conda install -c conda-forge category_encoders`\n",
    "* Seaborn (plotting)\n",
    "    - Run `pip install seaborn` or `conda install seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. You may continue :)\n"
     ]
    }
   ],
   "source": [
    "# Pre-flight checklist. Do not change this code.\n",
    "# Make sure that you have installed recent versions of key packages.\n",
    "# You could lose points if these checks do not pass.\n",
    "from packaging import version\n",
    "import sklearn\n",
    "import category_encoders\n",
    "import seaborn\n",
    "sklearn_version = sklearn.__version__\n",
    "catencoder_version = category_encoders.__version__\n",
    "if version.parse(sklearn_version) < version.parse(\"0.22.0\"):\n",
    "    print(\"scikit-learn is outdated. Please update now!\")\n",
    "if version.parse(catencoder_version) < version.parse(\"2.0.0\"):\n",
    "    print(\"category_encoders is outdated. Please update now!\")\n",
    "else:\n",
    "    print(\"OK. You may continue :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Speed Dating data. Takes a while the first time. Do not change this code!\n",
    "# Note that X is a pandas dataframe \n",
    "dates = openml.datasets.get_dataset(40536)\n",
    "X, y, _, feat_names = dates.get_data(target=dates.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup. Do not change this code!\n",
    "# Remove irrelevant or preprocessed columns \n",
    "cols = [c for c in X.columns if ((c.lower()[:2] != 'd_' or c.lower() == 'd_age') and c.lower() not in ['wave','has_null'])]\n",
    "X = X[cols]\n",
    "classes = ['No match','Match']\n",
    "\n",
    "# Fix feature name typos\n",
    "X = X.rename(columns={'ambtition_important': 'ambition_important',\n",
    "                     'sinsere_o': 'sincere_o'})\n",
    "\n",
    "# Harmonize the field names somewhat\n",
    "X['field'] = X['field'].str.lower()\n",
    "X = X.astype({'field': 'category'})\n",
    "\n",
    "# Drop columns with more than 10% missing values\n",
    "missing_counts = X.isnull().sum() * 100 / len(X)\n",
    "d = {k:v for (k,v) in missing_counts.items() if v>10}\n",
    "X.drop(d.keys(), axis=1, inplace=True)\n",
    "\n",
    "# Solves an implementation issue with TargetEncoder\n",
    "y=y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL BE HELPFUL\n",
    "# The list of the names of all categorical features\n",
    "categorical = X.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "# The list of the names of all numerical features\n",
    "numerical = X.select_dtypes(exclude=[\"category\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "Uncomment these lines to learn more about the data. Comment or remove to run the notebook faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at the remaining data\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the column data types and missing data\n",
    "# X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some categorical columns have a large number of possible values\n",
    "# Note: It looks like some manual cleaning should be done, but let's move on\n",
    "# X['field'].value_counts().plot(kind='barh', figsize=(5,40));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of numeric data\n",
    "# X.hist(layout=(20,4), figsize=(20,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do people find important? Is this related to the outcome (match / no match)?\n",
    "# import seaborn as sns\n",
    "# subset = ['attractive_important','ambition_important','attractive_partner','ambition_partner']\n",
    "# X_sub=X[subset]\n",
    "# X_sub['match'] = [classes[int(x)] for x in y] \n",
    "# sns.set(style=\"ticks\")\n",
    "# sns.pairplot(X_sub, hue=\"match\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 (5 points)\n",
    "Implement a function `simple_pipeline` that returns an sklearn pipeline that preprocesses the data in a minimal way before running a classifier:\n",
    "- Categorical features:\n",
    "    - Impute missing values by replacing them with the most frequent value for that feature\n",
    "    - Perform one-hot encoding. Use `sparse=False` to avoid that it returns a sparse datasets. Use `handle_unknown='ignore'` to ignore categorical values that where not seen during training.\n",
    "- Numeric features:\n",
    "    - Remove missing values by replace missing values with the mean value for that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def simple_pipeline(categorical, clf):\n",
    "    \"\"\" Returns a minimal pipeline that imputes missing values and does one-hot-encoding for categorical features\n",
    "    Keyword arguments:\n",
    "    categorical -- A list of categorical column names. Example: ['gender', 'country'].\n",
    "    clf -- any scikit-learn classifier\n",
    "    Returns: a scikit-learn pipeline which preprocesses the data and then runs the classifier\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check\n",
    "To be correct, this pipeline should be able to fit any classifier without error. Uncomment and run this code to do a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#simple_pipeline(categorical, DecisionTreeClassifier()).fit(X,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (1 point)\n",
    "How many features are being constructed by this pipeline (i.e. on how many features is the classifier trained)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, should be an integer. Don't change the name of the variable\n",
    "q_1_2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 (3 points)\n",
    "Implement a function `flexible_pipeline` that has two additional options:\n",
    "- Allow to add a feature scaling method for numeric features. The default is standard scaling. 'None' means no scaling\n",
    "- Allow the one-hot encoder to be replaced with another encoder, The default is one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "def flexible_pipeline(categorical, clf, scaler=StandardScaler(), encoder=OneHotEncoder()):\n",
    "    \"\"\" Returns a pipeline that imputes all missing values, encodes categorical features and scales numeric ones\n",
    "    Keyword arguments:\n",
    "    categorical -- A list of categorical column names. Example: ['gender', 'country'].\n",
    "    clf -- any scikit-learn classifier\n",
    "    scaler -- any scikit-learn feature scaling method (Optional)\n",
    "    encoder -- any scikit-learn category encoding method (Optional)\n",
    "    Returns: a scikit-learn pipeline which preprocesses the data and then runs the classifier\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 (3 points)\n",
    "Implement a function `plot_1_4` which plots a heatmap comparing several combinations of scaling methods and classifiers:\n",
    "* As classifiers, the following algorithms in their default hyperparameters settings: \n",
    "    * Logistic regression\n",
    "    * SVM with RBF kernel\n",
    "    * Random Forest\n",
    "* As options, the following feature scaling options in their default settings:\n",
    "    * No scaling\n",
    "    * Standard scaling\n",
    "    * Normalize\n",
    "    * PowerTransformer\n",
    "* In all cases, use OneHotEncoder with `sparse=False` and `handle_unknown='ignore'`\n",
    "\n",
    "You should evaluate all pipelines using AUC (area under the ROC curve) with 3-fold cross-validation. \n",
    "Compare all methods with the same cross-validation folds, shuffle the data and use `random_state=1`.\n",
    "Where possible, also use `random_state=1` for the classifiers. \n",
    "Only report the test scores (not the training scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper plotting function. Do not change.\n",
    "import seaborn as sns\n",
    "def heatmap(columns, rows, scores):\n",
    "    \"\"\" Simple heatmap.\n",
    "    Keyword arguments:\n",
    "    columns -- list of options in the columns\n",
    "    rows -- list of options in the rows\n",
    "    scores -- numpy array of scores\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(scores, index=rows, columns=columns)\n",
    "    sns.heatmap(df, cmap='RdYlGn_r', linewidths=0.5, annot=True, fmt=\".3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def plot_1_4(X, y):\n",
    "    \"\"\" Evaluates 3 classifiers together with 4 types of scaling. See description above.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5 (1 point)\n",
    "Interpret the heatmap of Question 1.4. Which of the following are correct?  \n",
    "Enter your answer as a comma-separated string without spaces, e.g. \"A,B,C\"\n",
    "- 'A': All scaling methods perform equally well. It doesn't matter which scaling method is used.\n",
    "- 'B': The best scaling method depends on the classifier that will be used.\n",
    "- 'C': Scaling is important for SVMs and logistic regression, but not needed for Random Forests.\n",
    "- 'D': The power transformer is much better than other techniques on this dataset because many features have a power law distribution.\n",
    "- 'E': The Normalizer works badly because information gets lost in the scaling.\n",
    "- 'F': No answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answers, e.g. 'A,B,C'. Don't change the name of the variable\n",
    "q_1_5 = 'F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.6 (3 points)\n",
    "Optimize the encoding method for the categorical features. Use your `flexible_pipeline` to compare OneHotEncoding and TargetEncoding\n",
    "together with the same 3 classifiers as in question 1.4. Always use standard scaling. Implement a function `plot_1_6` which plots a heatmap with the results.\n",
    "\n",
    "TargetEncoding is part of the category encoders extension of scikit-learn. [Read more about it.](https://contrib.scikit-learn.org/categorical-encoding/targetencoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "# Implement\n",
    "def plot_1_6(X, y):\n",
    "    \"\"\" Evaluates 3 classifiers and plots the results in a bar chart.\n",
    "    Also compares different category encoders\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.7 (1 point)\n",
    "Interpret the heatmap of Question 1.6. Which of the following are correct?  \n",
    "Enter your answer as a comma-separated string without spaces, e.g. \"A,B,C\"\n",
    "- 'A': They perform equally well\n",
    "- 'B': Target encoding is slightly better\n",
    "- 'C': One-hot-encoding is slightly better\n",
    "- 'D': It depends on the algorithm.\n",
    "- 'E': No answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answers, e.g. 'A,B,C'. Don't change the name of the variable\n",
    "q_1_7 = 'E'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.8 (1 point)\n",
    "How many features are being constructed by the target encoder pipeline (i.e. on how many features is the classifier trained)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, should be an integer. Don't change the name of the variable\n",
    "q_1_8 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature importance\n",
    "In this part, we will continue with your `flexible_pipeline`, and we use a random forest to learn which features\n",
    "are most important to predict the outcome of a dating 'match'. We will do this with both Random Forest's importance estimates and with permutation importance.\n",
    "\n",
    "### Question 2.1 (5 points)\n",
    "Implement a function `plot_2_1` that does the following:  \n",
    "* Split the data using a standard stratified and shuffled train-test split. Use `random_state=1`.\n",
    "* Combine your `flexible_pipeline`, without feature scaling but with one-hot-encoding, with a RandomForest classifier. Train that pipeline on the training set.\n",
    "* Remember that the categorical features where encoded. Retrieve their encoded names from the one-hot-encoder (with `get_feature_names`).\n",
    "* Retrieve the feature importances from the trained random forest and match them to the correct names. Depending on how you implemented your `flexible_pipeline` these are likely the first or the last columns in the processed dataset.\n",
    "* Compute the permutation importances given the random forest pipeline and the test set. Use `random_state=1` and at least 10 iterations.\n",
    "* Pass the tree-based and permutation importances to the plotting function `compare_importances` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function. Do not edit.\n",
    "def compare_importances(rf_importance, perm_importance, rf_feature_names, feature_names):\n",
    "    \"\"\" Compares the feature importances from random forest to permutation importance\n",
    "    Keyword arguments:\n",
    "    rf_importance -- The random forest's feature_importances_\n",
    "    perm_importance -- The permutation importances as computed by sklearn.inspection.permutation_importance\n",
    "    rf_feature_names -- The names of the features received by the random forest, in the same order as their importances\n",
    "    feature_names -- The original features names in their original order\n",
    "    \"\"\"\n",
    "    topk = 30\n",
    "    # Trees\n",
    "    sorted_idx = rf_importance.argsort()[-topk:]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    y_ticks = np.arange(0, topk)\n",
    "    ax[0].barh(y_ticks, rf_importance[sorted_idx])\n",
    "    ax[0].set_yticklabels(rf_feature_names[sorted_idx])\n",
    "    ax[0].set_yticks(y_ticks)\n",
    "    ax[0].set_title(\"Random Forest Feature Importances\")\n",
    "\n",
    "    # Permutations\n",
    "    sorted_idx = perm_importance.importances_mean.argsort()[-topk:]\n",
    "    ax[1].boxplot(perm_importance.importances[sorted_idx].T, vert=False, labels=feature_names[sorted_idx])\n",
    "    ax[1].set_title(\"Permutation Importances (test set)\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement\n",
    "def plot_2_1(X, y):\n",
    "    \"\"\" See detailed description above.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 (1 point)\n",
    "Interpret the results of Question 2.1. Which of the following are correct?  \n",
    "Enter your answer as a comma-separated string without spaces, e.g. \"A,B,C\"\n",
    "- 'A': The topmost feature importances are roughly the same for both methods\n",
    "- 'B': The topmost feature importances are very different\n",
    "- 'C': Categorical features (race, race_o, field,...) are ranked higher in the random forest ranking\n",
    "- 'D': Categorical features are ranked lower in the random forest ranking\n",
    "- 'E': No answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answers, e.g. 'A,B,C'. Don't change the name of the variable\n",
    "q_2_2 = 'E'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Calibrating predictions\n",
    "### Question 3.1 (2 points)\n",
    "Use a grid search to optimize the RandomForest pipeline from question 2.1. Vary the number of trees from 100 to 1500 and `max_features` from\n",
    "0.05 to 0.1. Use at least 2 values for every hyperparameter. Evaluate all pipelines using AUC (area under the ROC curve) with 3-fold cross-validation. Compare all methods with the same cross-validation folds, shuffle the data and use `random_state=1`.\n",
    "Plot the results in a heatmap in function `plot_3_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement\n",
    "def plot_3_1(X, y):\n",
    "    \"\"\" See detailed description above.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 (2 points)\n",
    "Implement a function `plot_3_2` that plots the ROC curve for the Random Forest pipeline with `n_estimators=1000`.\n",
    "Also indicate the point on the curve that corresponds to the 0.5 probability decision threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement\n",
    "def plot_3_2(X, y):\n",
    "    \"\"\" See description above.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3 (2 points)\n",
    "Calibrate your model to get a higher recall. What would be the optimal decision threshold (approximately) assuming that a false negative (missing a good match) is twice as bad as a false positive (going on a date with someone who is not a good match)? The grade will depend on the distance to the actual optimum (within a tolerance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the correct answer, should be a float. Don't change the name of the variable\n",
    "q_3_3 = 0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
